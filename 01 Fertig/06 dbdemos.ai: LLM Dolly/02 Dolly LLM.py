# Databricks notebook source
# MAGIC %md
# MAGIC
# MAGIC # Databricks Dolly - LLM
# MAGIC
# MAGIC <div style="text-align: left; line-height: 0; padding-top: 9px;">
# MAGIC   <img src="https://venturebeat.com/wp-content/uploads/2023/03/Untitled-design-29.png?w=1200&strip=all" alt="Dolly" style="width: 600px">
# MAGIC </div>

# COMMAND ----------

# MAGIC %md
# MAGIC
# MAGIC #databricks/dolly-v2-7b
# MAGIC
# MAGIC https://huggingface.co/databricks/dolly-v2-7b
# MAGIC
# MAGIC dolly-v2-7b is a 6.9 billion parameter causal language model created by Databricks that is derived from EleutherAI's Pythia-6.9b and fine-tuned on a ~15K record instruction corpus generated by Databricks employees and released under a permissive license (CC-BY-SA)

# COMMAND ----------

# MAGIC %pip install "accelerate>=0.16.0,<1" "transformers[torch]>=4.28.1,<5" "torch>=1.13.1,<2"

# COMMAND ----------

import torch
from transformers import pipeline

generate_text = pipeline(model="databricks/dolly-v2-7b", torch_dtype=torch.bfloat16, trust_remote_code=True, device_map="auto")

# COMMAND ----------

res = generate_text("Explain to me the difference between on-premise and cloud.")
print(res[0]["generated_text"])

# COMMAND ----------

res = generate_text("What should I pack for a trip to Spain?")
print(res[0]["generated_text"])

# COMMAND ----------

res = generate_text("What is Databricks?")
print(res[0]["generated_text"])

# COMMAND ----------

res = generate_text("Warum ist die AfD in Deutschland so beliebt?")
print(res[0]["generated_text"])

# COMMAND ----------

# MAGIC %md
# MAGIC
# MAGIC # Databricks Dolly Webinar (vom 26.04.2023, siehe Teams-Post von Michaela)
# MAGIC https://www.databricks.com/resources/webinar/emea-build-your-own-large-language-model-dolly
# MAGIC
# MAGIC <div style="text-align: left; line-height: 0; padding-top: 9px;">
# MAGIC   <img src="https://i.ibb.co/2v3tPm2/Dolly.jpg" alt="Dolly" style="width: 600px">
# MAGIC </div>
# MAGIC
